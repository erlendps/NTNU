# Eksamen Kont 2020

## Oppg 1

Hvis man bruker Select vil man oppnå en kjøretid på Theta(kn). Dette fordi Select finner det i-te laveste elementet og er garantert til å kjøre i lineær tid. Vi kan da finne det n-k minste elemenet opp til det n største elementet, totalt k ganger, ergo Theta(kn). Metoden er in-place og har ikke høyt minneforbrukt.
En annen opsjon kan være å bruke en sammenligningsbasert sorteringalgoritme. Ved å velge en lur algoritme, som mergesort eller heapsort, er man garantert til at kjøretiden er Theta(nlgn). Mergesort er en in-place algoritme som sorterer rekursivt, og vil derfor ikke ta mye plass i minnet. Heapsort derimot tar i bruk en haug, som da krever ekstra minne. Til gjengjeld er det mye enklere å hente ut elementene, som tar O(1) tid.
Hvis vi antar noe om inputet, slik som at det kommer fra et begrenset intervall, si 0 - n, så ville man kunne sortert i lineær tid ved å ta i bruk counting sort. Metoden antar at input kommer fra et begrenset intervall, og teller antall elementer som er mindre eller lik i. Dette krever ekstra lagringsplass og returner en ny array, men kan i et bra tilfelle som sagt kjøre i lineær tid.
Hva man faktisk velger avhenger litt av k. Dersom k nærmer seg n, så vil den første metoden ha kjøretid Theta(n²), og det ville vært raskere å brukt merge-sort og så returnere sub-arrayet A[k..n]. Jeg tror det beste hadde vært å brukt en in-place sorteringsalgoritme som ikke bruker ekstra plass som implemenmtasjonen. Merge-sort er da en god kandidat.

## Oppg 2

Det er to forskjellige problemer. Å koble sammen alle noder i en graf med minst mulig totalvekt er et minimalt spenntre, og vi har gode algoritmer (prim, kruskal) for å løse dette. Det andre problemet er et korteste vei-problem, og man kan bruke Bellman-Ford eller Djikstra for å løse dette problemet. 
Problemene ligner på hverandre, men det å danne et minimalt spenntre er ikke ekvivalent med å finne korteste vei. Dette er fordi algoritmene for å genere et minimalt spenntre er grådige algoritmer, det vil si at de velger det som ser lokalt best ut, og det viser seg at det også er det beste globalt. Dette er ikke tilfellet for korteste-vei problemet, da dette problemet ikke har grådighetsegenskapen. Hvis man hadde hatt n noder som var seriekoblet fra u til v, alle med vekt 1. I tillegg er det en kant mellom u og v med vekt 2. Et minimalt spenntre ville funnet seriekoblingen, og vekten fra u til v ville vært n. Derimot ville en korteste-vei algoritme funnet at den korste veien er bare u til v direkte og hatt totalvekt 2. I tillegg så fungerer ikke prim eller kruskal på rettede grafer, men kantevektene kan være negative og ha sykler. Korteste vei problemet har noen flere begrensinger, avhengig av algoritmen. Djikstra fungerer ikke med negative kantvekter, men på både rettede og urettede grafer. Bellman-Ford vil si ifra om en graf har negative sykler (og ikke gi løsning), aksepterer negative kantvekter og grafen kan være både rettet og urettet. DAG må være rettet og asyklisk.

## Oppg 3

Det relaterer seg, og er spesielt vanlig i f.eks rekursive algoritmer. Splitt og hersk er en designmetode som veldig gjerne splitter en instans inn i flere, mindre delinstaner, og er ofte rekursive algoritmer. Spesielt for denne delstrukturen er at delproblemene er uavhengige, og ikke overlapper. Det vil si at to forskjellige dekomponeringer ikke resulterer i samme delproblem etter hvert. Til det ville man heller brukt dynamisk programmering eller memorisering, som tar vare på resultatet fra en delinstans, og tar det opp igjen når man møter det på nytt. En siste designmetode er grådige algoritmer, der man for hver delinstans velger den løsningen som gir lokalt optimum. Dette krever at problemet og strukturen har grådighetsegenskapen. Det vil si at et lokalt optimum viser seg å være en del av et globalt optimum. 
Den matematiske induksjonen spiller en stor rolle for å bevise at man får et korrekt svar ved å dekomponere til delinstanser. Ofte når man dekomponerer så får man rekurrenser, og ved bruk av matematisk induksjon kan man vise at dersom det gjelder for en vilkårlig n, så vil det også gjelde for n+1, og dermed for alle n. Så induksjon er en måte å bevise at dekomponeringen vi gjør faktisk er riktig.
Det har vel på en måte slektskap til reduksjon og hardhetsbevis, med at man dekomponerer til et mer spesielt tilfelle av et problem. For eksempel så kan man redusere å finne lengste vei (et mer generelt problem) til å finne en hamilton-sykel. Siden Ham-Cycle er np-komplett, er også det å finne lengste vei np-komplett. 
NP-kompletthet går jo også på beslutningsproblem, og ikke optimeringsproblem, altså man stiller ja/nei spørsmål. Man må da transformere en optimeringsproblem til et bestlutnignsproblem, og i mange tilfeller er dette veldig greit. Da kan man også tenke seg at man kan dekomponere problemet i flere delinstanster, og spørre om denne delinstansen har denne egenskapen.

## Oppg 4

Metoden hans vil fungere. Spørsmålet er hvorvidt denne er effektiv. Man legger til noder og kanter for hver sti. Vi kan representere dette med en funksjon h(k) som sier hvor mange noder og kanter ekstra det krever, for hver kant (u,v). Dette vil i alle tilfeller for k > 1 være k-1. Siden k kan være forskjellig fra kant til kant, kan man anta et gjennomsnitt av k-ene, m. Kjøretiden vil da bli O(|E|(m-1) + |V|(m-1)).Dersom m-1 nærmer seg enten |E| eller |V| vil denne algoritmen ha en høyere kjøretid enn de fleste korteste-vei algoritmer. Det kreves også mer lagringsplass, siden vi må ekspandere køen vår i BFS. For små m, si for eksempel m=3, så vil man bare få en konstant faktor, og kjøretiden vil være bedre enn de fleste algoritmer. Om grafen inneholder sykler og vekten er små nok, så vil denne algoritmen ha ca samme kjøretid som DAG-shortest path. Den vil ha raskere kjøretid enn Dijsktra, gitt selvfølgelig at m er liten nok. Dersom alle vektene også er delelig på et tall, kan vi dele på dette tallet for alle vektene, og forhåpentligvis har man da også fått en mindre m som vil bedre kjøretiden.
Heltallsteoremet sier at dersom alle kapasiteter er et heltall, så vil flyten gjennom hver node, samt den totale flyten også være et heltall om man bruker Ford-Fulkersons metode.
Jeg antar at med en lignende metode, så menes det en metode som gjør om en kant (u,v) til en sti med lengde k, der hver node i stien har lengde 1. Dette vil ikke fungere i maksimal flyt problemet. Dette er fordi når alle kantene ville hatt kapasitet 1 da, og det vil da nødvendigvis ikke finne den maksimale flyten i grafen.

## Oppg 5

Fordelen med dette er at man får et univers der problemene enten er løselig i polynomisk tid, eller det går an å verifisere (men ikke løse) i polynomisk tid. Med verifisere mener man at man sjekker opp mot et sertifikat, f.eks er det enkelt å verifisere om en gitt sekvens av noder er en hamilton-sykel, men det er NP-hardt å løse problemet. Ulempen er at man ikke vet om alle problemer i NP kan løses i polynomisk tid eller ikke.
NP er som sagt problemer som kan verifiseres i polynomisk tid. Intuitivt kan man tenke at det er mye lettere å verifisere en løsning enn å finne en løsning fra bunnen av. Det vil derfor være naturlig å tro at dette også vil gjelde for NP, og at det av den grunn er større enn P, og generelt en stor klasse. 
For at et problem skal være i NP må det være et beslutningsproblem. Traveling Salesman er et NP-problem, men f.eks en optimeringsversjon av TSM vil være vanskeligere enn TSM der man bare finner ut om det er mulig eller ikke. Et slik problem vil være NP-hardt, men ikke NP. Dette har likevel stor betydning, ettersom man kan redusere til et slikt problem, og man kan da vise at et problem A redusert til problem B, der B er NP-hardt, er også A NP-hardt. Vi bruker da gjerne NP-klassen til å bestemme om et problem er bare NP-hardt eller også NP-komplett. Dersom et problem A er både NP-hardt (det vil si kan reduseres til et kjent NP-hardt problem), og A kan verifiseres i polynomisk tid og er et beslutningsproblem, så er A NP-komplett.
