# Exam 2021

## Task 1

a)
$$
\begin{aligned}
&Initial\_state: S\\
&States: \{S, B, C, H, G\} \\
&Actions: \{ \\
& \ \ Actions(S)= \{ToB, ToC\} \\
& \ \ Actions(B)= \{ToS, ToC, ToG\} \\
& \ \ Actions(C)= \{ToS, ToB, ToH, ToG\} \\
& \ \ Actions(H)= \{ToC, ToG\} \\
& \ \ Actions(G)= \{ToB, ToC, ToH\} \\
&\} \\
&Path\_cost: \{\\
& \ \ Action-Cost(S, ToB, B) = Action-Cost(B, ToS, S) = 1,\\
& \ \ Action-Cost(S, ToC, C) = Action-Cost(C, ToS, S) = 3,\\
& \ \ Action-Cost(B, ToC, C) = Action-Cost(C, ToB, B) = 1,\\
& \ \ Action-Cost(B, ToG, G) = Action-Cost(G, ToB, B) = 9,\\
& \ \ Action-Cost(C, ToH, H) = Action-Cost(H, ToC, C) = 2,\\
& \ \ Action-Cost(C, ToG, G) = Action-Cost(G, ToC, C) = 5,\\
& \ \ Action-Cost(H, ToG, G) = Action-Cost(G, ToH, H) = 1,\\
&\}\\
&Transistion\_model: \{\\
& \ \ Result(S, ToB) = B,\\
& \ \ Result(S, ToC) = C,\\
& \ \ Result(B, ToS) = S,\\
& \ \ Result(B, ToC) = C,\\
& \ \ Result(B, ToG) = G,\\
& \ \ Result(C, ToS) = S,\\
& \ \ Result(C, ToB) = B,\\
& \ \ Result(C, ToH) = H,\\
& \ \ Result(C, ToG) = G,\\
& \ \ Result(H, ToC) = C,\\
& \ \ Result(H, ToG) = G,\\
& \ \ Result(G, ToH) = H,\\
& \ \ Result(G, ToB) = B,\\
& \ \ Result(G, ToC) = C,\\
&\}\\
&Goal\_test: G
\end{aligned}
$$

b) Graph version of A*, assumes then that this means it checks whether the node is in the closed list, in which case it does not reexpand.

1. Expanded: S, Frontier: [C, B], Closed: []
1. Expanded: C, Frontier: [B, H, G], Closed: [S]
1. Expanded: B, Frontier: [H, G], Closed: [S, C]
1. Expanded: H, Frontier: [G], Closed: [S, C, B]
1. Expanded: G, Frontier: [], Closed: [S, C, B, H]

c) The returned path will be [S, C, H, G], giving a cost of 6. This is not the optimal path, as it is one path that is shorter ([S, B, C, H, G]). It is not the optimal path since for the graph-version of A*, where we are not allowing reexpansion of nodes, the heuristic function needs to be consistent to guarantee finding a cost-optimal solution. The heuristic given is admissible, but this is not enoguh, since we are not guaranteed that when we first explore a node, we explore it through the most optimal path. 

For the solution to be optimal, we have to make the heuristic consistent, that is for each node $n$ and each neighbor $m$ of $n$ we have: $h(n) \leq cost(n, a, m) + h(m)$. In fact, we only need to change h(c) from 1 to 3 to make the heuristic consistent. Then h(s) <= h(b) + 1, h(s) <= h(c) + 3, h(b) <= h(c) + 1, h(b) <= h(g) + 9, h(c) <= h(h) + 2, h(c) <= h(g) + 5, h(g) <= h(g) + 1.

d) See notes

e) 
1 ) None of the nodes are pruned using alpha-beta pruning. This is because every value in one subtree is higher than the lowest value in the subtree to the left. Resuting in zero prunings.

2 ) Firstly, for each subtree that contains only leaves, place the leaf with the lowest value first, i.e for the leftmost subtree, the ordering becomes: 1, 100, 99. Then, we order such that the order from left to right (with emphasis on the subtrees) is in descending order, based on that subtrees minimum value. That is we get the ordering (minimum value): 5, 4, 3, 2, 1. This way, we will be able to prune 9 nodes, because the first node we explore in each subtree (excluding the now leftmost) will have a value that is lower than the leftmost subtree's minimum value, meaning the max-agent never will choose the action leading to this subtree.

f) Breadth first uses the eval-function f(n) = depth, and chooses the lowest of these.

1. Expanded: S, Frontier: [A, B, C]
1. Expanded: A, Frontier: [B, C]
1. Expanded: B, Frontier: [C, D, E]
1. Expanded: C, Frontier: [D, E]
1. Expanded: D, Frontier: [E]

With an early goal test, we conclude the path is [S, C, D, G]. This however is not the optimal solution. This is because of the early goal test, overwriting of parent (where it came from) and ordering for ties. Breadth-first finds the path with the lowest visited nodes, and is cost-optimal only if the edge-costs are all equal. When it is not, as in this case, it does not necessarily find the optimal solution.

## Task 2

a) I choose predicate logic because I think it will be easier to read in a natural language. I also have the advantage (for representation of this problem) of only having a single predicate, namely $At(object, tile)$, which means the object is at tile. It is also less to write. To fully represent the state using propositional logic, you would have to for each tile have a conjunction of proposistions, such as $\neg Player_{x,y} \wedge Sparkles_{x,y} \wedge ...$
The state is then:
$$
\begin{aligned}
&At(Sparkles, (1,1)),\\
&At(Diamond, (1,2)),\\
&At(RedGlow, (1,2)),\\
&At(Lava, (1,3)),\\
&At(Sparkles, (1,3)),\\
&At(RedGlow, (2,1)),\\
&At(Sparkles, (2,2)),\\
&At(Sparkles, (2,3)),\\
&At(RedGlow, (2,3)),\\
&At(Lava, (3,1)),\\
&At(RedGlow, (3,2)),\\
&At(Player, (3,2)),\\
&At(Sparkles, (3,2)),\\
&At(Diamond, (3,3))\\
\end{aligned}
$$

b)
$Adjecent(x,y)$ means that tile $x$ is adjacent to tile $y$.

1. $\forall x, y \ ((At(Diamond, y) \wedge Adjecent(x,y)) \implies At(Sparkles, x))$
1. $\forall x, y \ ((At(Lava, y) \wedge Adjecent(x,y)) \implies At(RedGlow, x))$
1. $\forall x ((At(Player, x) \wedge At(Lava, x)) \implies GameOver)$
1. $\neg \exists x \ At(Diamond, x) \implies YouWin$
1. $\forall x \ ((At(Player, x) \wedge At(Diamond, x)) \implies HasDiamondAt(x))$
1. $\forall x, y \ ((Adjacent(x, y) \wedge At(RedGlow, y)) \implies \exists z \ (Adjacent(x, z) \wedge At(Sparkles, z))) \implies CanMoveTo(x)$
1. $\forall x,y \ ((Adjacent(x, y) \wedge At(Player, y)) \implies CanMoveTo(x))$

c) Yes it is possible. I assume that when you find a diamond the sparkles disappear, and also that you don't remember which tiles are safe. You can then make your way to the diamond at (2, -1). It is important that you dont take the other diamonds on the way, as it would lead to a deadend. Then you can take the diamond at (1,2)

No it is not possible, when you take the diamond at (2, -1), which is the first diamond you have to take, then when you try to get to (2, 0) the rules wont allow you, since (2,0) no longer is adjecent to a square with sparkles.

d) Rule a, b and d are already on CNF.
For rule c:
Remove implication
$\forall x \forall y (\neg(Person(x) \wedge Afraid(x, y)) \vee \neg Close(x, y))$

Move negation inwards:
$\forall x \forall y (\neg Person(x) \vee \neg Afraid(x, y) \vee \neg Close(x, y))$

Now we can safely remove universal quantifiers:
$\neg Person(x) \vee \neg Afraid(x, y) \vee \neg Close(x, y)$

For rule e:
Remove implication:
$\forall x \forall y \forall z \ (\neg(Close(x,y) \wedge Close(y,z)) \vee Close(x,z))$

Move negation inwards:
$\forall x \forall y \forall z \ (\neg Close(x,y) \vee \neg Close(y,z) \vee Close(x,z))$

Universal instansitation:
$\neg Close(x,y) \vee \neg Close(y,z) \vee Close(x,z)$

For rule f:
Remove implication:
$\forall x \forall y \ (\neg Close(x, y) \vee Close(y, x))$

Universal instansiation:
$\neg Close(x, y) \vee Close(y, x)$

For rule g:
Remove implication:
$\forall x \ (\neg CanMine(x, Diamonds) \vee Close(x, Diamonds))$

Universal instansiation:
$\neg CanMine(x, Diamonds) \vee Close(x, Diamonds)$

We wish to prove the sentence Richard does not mine diamonds, i.e $\neg CanMine(Richard, Diamonds)$. We do this by refutation, in which we need the negated goal: $CanMine(Richard, Diamonds)$

We start with rule c and b:
$\neg Person(x) \vee \neg Afraid(x, y) \vee \neg Close(x, y) \vee Person(Richard)$

We make the substitution $\theta = \{x/Richard\}$, which makes the above resolve to:

$\neg Afraid(Richard, y) \vee \neg Close(Richard, y)$

Then we use rule a with a new resolution:

$\neg Afraid(Richard, y) \vee \neg Close(Richard, y) \vee Afrad(Richard, Lava)$

With the substitution $\theta = \{y/Lava\}$ it resolves to:

$\neg Close(Richard, Lava) \ \ \ \ (h)$

Then we use rule e:
$\neg Close(Richard, Lava) \vee \neg Close(x,y) \vee \neg Close(y,z) \vee Close(x,z)$

And use $\theta = \{x/Richard, z/Lava\}$ we resolve to

$\neg Close(Richard,y) \vee \neg Close(y,Lava)$

Then we use rule d:

$\neg Close(Richard,y) \vee \neg Close(y,Lava) \vee Close(Diamonds, Lava)$

and the substitution $\theta = \{y/Diamonds\}$ it resolves to:

$\neg Close(Richard, Diamonds)$

We then resolute with rule g:

$\neg CanMine(x, Diamonds) \vee Close(x, Diamonds) \vee \neg Close(Richard, Diamonds)$

with $\theta = \{x/Richard\}$ gives the resolvent:

$\neg CanMine(Richard, Diamonds)$

Lastly we do a resolution with the negated goal:

$\neg CanMine(Richard, Diamonds) \vee CanMine(Richard, Diamonds)$

which resolves to the empty set which is a contradiction, meaning Richard does not mine diamonds.

e)
a. Satisfiable. it's either true or false.
b. Unsatisfiable. They are always opposite, so one is always false, so everything is false.
c. Valid. They are always oppsite, so one will awlays be true
d. Valid. False implies false and true imples true.
e. Satisfiable. They are the same for 2 models.
f. Satisfiable. True for every models that is false in e.
g. Satisfiable. For RG=0 and D=1 we get true implies false, which is false.

## Task 3

a)
D(Peter) = {LG-Calat1, LG-Calat2, LG-Phil1}
D(Anette) = {B-Phil2, V-Calat3, DG-Calat3}
D(Rudolf) = {B-Phil2, V-Phil1, V-Calat1}
D(Daisy) = {V-Calat1, B-Phil2}
D(Femke) = {V-Phil1, V-Calat1, V-Calat2, V-Calat3, DG-Phil1, DG-Calat1, DG-Calat2, DG-Calat3, Y-Phil1, Y-Calat1, Y-Calat2, Y-Calat3}

Calat1:
D(Peter) = {LG-Calat1, #LG-Calat2, LG-Phil1}
D(Anette) = {B-Phil2, #V-Calat3, DG-Calat3}
D(Rudolf) = {B-Phil2, #V-Phil1, #V-Calat1}
D(Daisy) = {V-Calat1, #B-Phil2}
D(Femke) = {#V-Phil1, #V-Calat1, #V-Calat2, #V-Calat3, DG-Phil1, #DG-Calat1, #DG-Calat2, DG-Calat3, Y-Phil1, #Y-Calat1, #Y-Calat2, Y-Calat3}

## Task 4

1 )
a) Flaw 1: The plan has no plan if the precondition SMooth(B) does not hold, i.e there is no plan for sanding B.
Flaw 2: The plan allows for putting A on B before one of them are painted.
Flaw 3: It can try to paint a chair when its not smooth

b) Flaw 1: Add something similar for A to B, i.e add a path that sands the chair. Free(B);Sand(B);Smooth(B)
Flaw 2: Move the putOn action after the chairs have been painted.
Flaw3: Remove the line from Free(A/B) to Paint(A/B)

c) start ; (sand(A) AND sand(B)) ; (paint(A) AND paint(B)) ; putOn(A, B) ; finish.

2 ) None, if terminates in the first layer order does not matter.

3 ) start;tik;finish

4 )

## Task 6

1 )
a)

Eval(a) = 1 - (1 + 1 + 1 + 1 + 1) = -4
Eval(b) = 1 - (1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1) = -9

b) It will move with probability $e^{\Delta e/T} = e^{-5/4} = 0.29$

2 )
It really depends on how you define the consuquence and what is a good and bad consequence. Search-algorithms for finding the cost-optimal path can for example save us alot of time, resulting in lower emission and less time wasting. However, terrorist can also define a good consequence to what other define as bad.

3 )
P - effectively drop stones on the correct location to blow up as many mines as possible, safe, fast
E - water, different depths, weather, waves, other boats
A - steering, dropping-mechanism, oberserver-sensors, gps
S - acellerometer, gps, lidar, ekko-sensors

The environment is single-agent, stochastic, continous, sequantial, partially-observable, dynamic and known.

4 )
$\forall x Member(x, Elephant) \implies Member(x, Mammal)$
$IsColorWhite(Clyde)$
$\forall x IsColorGrey(Member(x, Elephant))$
